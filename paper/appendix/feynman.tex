

In this section, we introduce the Feynman-Kac convention of \cite{delMoral04} that has since become commonplace \citep{karjalainen23} for the analysis of the particle filter. The mathematical formalization and notation introduced here will be adopted in the remainder of the analysis, in order to prove Theorems \ref{thm:mop-targeting}, \ref{thm:mop-grad-consistency}, and \ref{thm:mop-biasvar}. Let $(\eta_n)_{n=1}^N, (\pi_n)_{n=1}^N, (\rho_n)_{n=1}^N$ be sequences of probability measures on the state space $\gX$. This is the sequence of prediction distributions $f_{X_{n}|Y_{1:n-1}}$, filtering distributions $f_{X_{n}|Y_{1:n}}$, and posterior distributions $f_{X_{1:n}|Y_{1:n}}$ that we seek to approximate with the particle filter. For any measurable bounded functional $h$, we adopt the following functional-analytic notation, borrowed from \cite{delMoral04, chopin20, karjalainen23}. We choose our specific choice of notation and definitions to be in line with that of \cite{karjalainen23}. 


\paragraph{\bf Markov kernels and the process model:} A Markov kernel $M$ with source $\gX_1$ and target $\gX_2$ is a map $M: \gX_1 \times \mathcal{B}(\gX_2) \to [0,1]$ such that for every set $A \in \mathcal{B}(\gX_2)$ and every point $x \in \gX_1$, the map $x \mapsto M(x, A)$ is a measurable function of $x$, and the map $A \mapsto M(x,A)$ is a probability measure on $\gX_2$. The quantity $M(x,A)$ can be thought of as the probability of transitioning to the set $A$ given that we are at the point $x$. If this yields a density, this then corresponds to the process density $f_{X_{2}|X_1}$ conditional on $x$ and integrated over $A$.  

\paragraph{\bf Markov kernels and measures:} For any measure $\eta$, any Markov kernel $M$ on $\gX$, any point $x \in \gX$ and any measurable subset $A \subseteq \gX$, let 
\begin{align}
    \eta(h) &= \int h \, d\eta = \int h(x) \eta(dx), \\(\eta M)(A) &= \int \eta(dx)M(x,A), \\
    (Mh)(x) &= \int M(x, dy) h(y).
\end{align}

\paragraph{\bf Compositions of Markov kernels:} The composition of a Markov kernel $M_1$ with another Markov kernel $M_2$ is another Markov kernel, given by 
\begin{equation}
 (M_1M_2)(x, A) = \int M_1(x, dy) M_2(y, A).
\end{equation}

\paragraph{\bf Total variation distance:} The total variation distance between two measures $\mu$ and $\nu$ on $\gX$ is
\begin{equation}
\|\mu-\nu\|_{\mathrm{TV}}=\sup _{\|h\|_{\infty} \leq 1 / 2}|\mu(\phi)-\nu(\phi)|=\sup _{\operatorname{osc}(h) \leq 1}|\mu(h)-\nu(h)|.    
\end{equation}

\paragraph{\bf Dobrushin contraction:} The Dobrushin contraction coefficient $\beta_{\text{TV}}$ of a Markov kernel $M$ is given by
\begin{equation}
\beta_{\mathrm{TV}}(M)=\sup _{x, y \in \gX}\big\|M(x, \cdot)-M(y, \cdot)\big\|_{\mathrm{TV}}=\sup _{\mu, \nu \in \mathcal{P}, \mu \neq \nu} \frac{\|\mu M-\nu M\|_{\mathrm{TV}}}{\|\mu-\nu\|_{\mathrm{TV}}}.    
\end{equation}

\paragraph{\bf Potential functions and the measurement model:} A potential function $G : \gX \to [0,\infty)$ is a non-negative function of an element of the state space $x \in \gX$. 
In our case, this corresponds to the measurement model, and in our previous notation is written as $g_{n,j} = f_{Y_n|X_n}(y_n^*|x_{n,j}^F) = G_n(x_{n,j}^F)$, where in a slight abuse of notation we suppress the dependence on $\theta$ for notational simplicity. 
Note that $G_n(\cdot) = f_{Y_n|X_n}(y_n^*|\;\cdot\;)$ is the conditional density of the observed measurement at time $n$, where we condition on the filtering particle $x_{n,j}^F$ as an element of the state space. 

\paragraph{\bf Feynman-Kac models:} A Feynman-Kac model on $\gX$ is a tuple $(\pi_0, (M_n)_{n=1}^N, (G_n)_{n=1}^N)$ of an initial probability measure on the state space $\pi_0$, a sequence of transition kernels $(M_n)_{n=1}^N$, and a sequence of potential functions $(G_n)_{n=1}^N$. In the notation used in the main text, this corresponds to the starting distribution $f_{X_0}$, the sequence of transition densities $f_{X_{n}|X_{n-1}}$, and the measurement densities $f_{Y_n|X_n}$. This induces a set of mappings from the set of probability measures on $\gX$ to itself, $\mathcal{P}(\gX) \to \mathcal{P}(\gX)$, as follows:
\begin{itemize}
    \item The update from the prediction to the filtering distributions is given by 
    \begin{equation}
    \pi_n(dx) = \Psi_n(\eta_n)(dx) = \frac{G_n(x)\cdot\eta_n(dx)}{\eta_n(G_n)}.
    \end{equation}
    \item The map from the prediction distribution at timestep $n$ to timestep $n+1$ is given by 
    \begin{equation}
 \Phi_{n+1}(\eta_n) = \Psi_n(\eta_n) M_{n+1}.       
    \end{equation}
    \item The composition of maps between prediction distributions yields the map from the prediction distribution at time $k$ to the prediction distribution at time $n$ where $k \leq n$,
    \begin{equation}
 \Phi_{k,n} = \Phi_n \circ ... \circ \Phi_{k+1}.       
    \end{equation}
\end{itemize}
\paragraph{\bf The particle filter:} The particle filter then yields a Monte Carlo approximation to the above Feynman-Kac model, via a sequence of mixture Dirac measures. When one resamples at every timestep, the prediction measure at timestep $n$ is then given by 
\begin{equation}
\eta_n^J = \frac{1}{J}\sum_{j=1}^J \delta_{x_{n,j}^P},
\end{equation}
and the filtering measure at timestep $n$ is given by
\begin{equation}
\pi_n^J = \frac{\sum_{j=1}^J g_{n,j} \delta_{x_{n,j}^P}}{\sum_{j=1}^J g_{n,j}} \approx \frac{1}{J} \sum_{j=1}^J \delta_{x_{n,j}^F}.
\end{equation}
In a slight abuse of notation, we will identify $x_{n, 1:J}^P \equiv \eta_n^J$, and $x_{n, 1:J}^F \equiv \pi_n^J$. 
As in \cite{karjalainen23}, one can view this as an inhomogenous Markov process evolving on $\gX^{J}$. The corresponding Markov transition kernel is then 
\begin{equation}
\textbf{M}_n(x_{n-1, 1:J}^P, \cdot) = \left(\Phi_{n}\left(\eta_n^J\right)\right)^{\otimes J} = \left(\Phi_{n}\left(\frac{1}{J}\sum_{j=1}^J \delta_{x_{n,j}^P}\right)\right)^{\otimes J},
\end{equation}
and the composition of Markov kernels on particles from timestep $n$ to timestep $n+k$ is written 
\begin{equation}
\textbf{M}_{n, n+k} = \textbf{M}_{n+k}\circ ...\circ \textbf{M}_n.
\end{equation}
One may wonder why \cite{karjalainen23} require this process to evolve on $\gX^{J}$. This is because at every timestep $n$, we in fact draw $X_{n, j}^P | \{X_{n-1, 1:J}^P = x_{n-1, 1:J}^P\} \sim \textbf{M}_n(x_{n-1, 1:J}^P, \cdot) = \eta_0^{\otimes J} \textbf{M}_{0,n}$ for $j=1,...,J$. 

\paragraph{\bf Forgetting of the particle filter:} 
The above formalization yields a result from \cite{karjalainen23} on the forgetting of the particle filter that we require for our analysis of the bias, variance, and error of MOP-$\alpha$.  
That is, \cite{karjalainen23} show that
\begin{equation}
\beta_{\mathrm{TV}}\left(\mathbf{M}_{n, n+k}\right) \leq(1-\epsilon)^{\lfloor k /(O(\log J))\rfloor},
\end{equation}
for some $\epsilon$ dependent on $\bar{G}, \underbar{G}, \bar{M}, \underbar{M}$ in Assumptions \ref{assump:bounded-measurement} and \ref{assump:bounded-process}. As a result, the mixing time of the particle filter is only on the order of $O(\log(J))$ timesteps. 


\vspace{3mm}

Equipped with the above formalisms and results, we are now in a position to provide guarantees on the performance of MOP-$\alpha$ itself. 