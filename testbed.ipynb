{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa8e083e-955f-4fba-a679-4785b3bcf58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#import numba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "plt.style.use('matplotlibrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d292e62-58b3-42ad-8921-044380304216",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = pd.read_csv('cases.csv')['cases'].values\n",
    "covars = pd.read_csv('covars.csv')\n",
    "covars = covars[['seas1', 'seas2', 'seas3', 'seas4', 'seas5', 'seas6']].values[:cases.shape[0],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8414c4-ae5f-45aa-b98d-90c4e3bbfe42",
   "metadata": {},
   "source": [
    " rho           tau         beta1         beta2         beta3         beta4         beta5         beta6            nu         gamma \n",
    " 7.617542e-01  2.660769e+02  1.437621e+00  1.290241e+00  1.167740e+00  1.275811e+00  1.361995e+00  1.153047e+00  9.648961e-01  3.500000e+00 \n",
    "        sigma        theta0         alpha            mu         delta        sig_sq           S_0           E_0           I_0           A_0 \n",
    " 5.000000e+00  0.000000e+00  2.397300e-03  4.287000e-04  1.433000e-04  1.041514e-01  9.993196e-01  1.834793e-04  4.969569e-04  0.000000e+00 \n",
    "          R_0         pop_0         betat \n",
    " 0.000000e+00  1.091182e+07 -6.717172e-02 \n",
    " \n",
    " \n",
    " beta1 = .02, beta2 = .02, beta3 = .02,\n",
    "                beta4 = .02, beta5 = .02, beta6 = .02,\n",
    "                tau = 0.02, rho = 0.02, nu = 0.02, sig_sq = 0.02,\n",
    "                E_0 = ivp(0.2), I_0 = ivp(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dfaaac4-d439-472c-9dc1-bbf3e1a68293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rho</th>\n",
       "      <td>7.617542e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau</th>\n",
       "      <td>2.660769e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta1</th>\n",
       "      <td>1.437621e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta2</th>\n",
       "      <td>1.290241e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta3</th>\n",
       "      <td>1.167740e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta4</th>\n",
       "      <td>1.275811e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta5</th>\n",
       "      <td>1.361995e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta6</th>\n",
       "      <td>1.153047e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nu</th>\n",
       "      <td>9.648961e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma</th>\n",
       "      <td>3.500000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>2.397300e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu</th>\n",
       "      <td>4.287000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta</th>\n",
       "      <td>1.433000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sig_sq</th>\n",
       "      <td>1.041514e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S_0</th>\n",
       "      <td>9.993196e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E_0</th>\n",
       "      <td>1.834793e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I_0</th>\n",
       "      <td>4.969569e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R_0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_0</th>\n",
       "      <td>1.091182e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>betat</th>\n",
       "      <td>-6.717172e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "rho     7.617542e-01\n",
       "tau     2.660769e+02\n",
       "beta1   1.437621e+00\n",
       "beta2   1.290241e+00\n",
       "beta3   1.167740e+00\n",
       "beta4   1.275811e+00\n",
       "beta5   1.361995e+00\n",
       "beta6   1.153047e+00\n",
       "nu      9.648961e-01\n",
       "gamma   3.500000e+00\n",
       "sigma   5.000000e+00\n",
       "theta0  0.000000e+00\n",
       "alpha   2.397300e-03\n",
       "mu      4.287000e-04\n",
       "delta   1.433000e-04\n",
       "sig_sq  1.041514e-01\n",
       "S_0     9.993196e-01\n",
       "E_0     1.834793e-04\n",
       "I_0     4.969569e-04\n",
       "A_0     0.000000e+00\n",
       "R_0     0.000000e+00\n",
       "pop_0   1.091182e+07\n",
       "betat  -6.717172e-02"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = pd.read_csv('params.csv')\n",
    "params.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1da681bf-d22a-4501-a9c0-4ab0ee6b32f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class diffRound(torch.autograd.function.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.input = input\n",
    "        return torch.round(input).int()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_input = grad_output.clone()\n",
    "        return grad_input\n",
    "    \n",
    "class Haiti1(nn.Module):\n",
    "    def __init__(self, covars, cases, params, dt):\n",
    "        super().__init__()\n",
    "        self.cases = torch.tensor(cases)\n",
    "        self.covars = torch.tensor(covars)\n",
    "        \n",
    "        #trainable params\n",
    "        self.betas = nn.Parameter(torch.tensor([params['beta1'], params['beta2'], \n",
    "                                                params['beta3'], params['beta4'], \n",
    "                                                params['beta5'], params['beta6']]).squeeze())\n",
    "        self.betat = nn.Parameter(torch.tensor(params['betat']))\n",
    "        self.rho = nn.Parameter(torch.tensor(params['rho']))\n",
    "        self.tau = nn.Parameter(torch.tensor(params['tau']))\n",
    "        self.nu = nn.Parameter(torch.tensor(params['nu']))\n",
    "        self.sig_sq = nn.Parameter(torch.tensor(params['sig_sq']))\n",
    "        self.E_0 = nn.Parameter(torch.tensor(params['E_0']))\n",
    "        self.I_0 = nn.Parameter(torch.tensor(params['I_0']))\n",
    "        \n",
    "        self.S = torch.tensor(params['S_0']).double() * torch.tensor(params['pop_0'])\n",
    "        self.E = self.E_0 * torch.tensor(params['pop_0'])\n",
    "        self.I = self.I_0 * torch.tensor(params['pop_0'])\n",
    "        self.R = torch.tensor(params['R_0']).double() * torch.tensor(params['pop_0'])\n",
    "        self.incid = 0\n",
    "        self.foival = 0\n",
    "        \n",
    "        self.mu = torch.tensor(params['mu'])\n",
    "        self.delta = torch.tensor(params['delta'])\n",
    "        self.sigma = torch.tensor(params['sigma'])\n",
    "        self.gamma = torch.tensor(params['gamma'])\n",
    "        self.alpha = torch.tensor(params['alpha'])\n",
    "        self.t = 0\n",
    "        self.dt = dt\n",
    "        \n",
    "    #@torch.jit.script_method\n",
    "    def reulermultinom(self, N: int, rates, dt: float, save=False):\n",
    "        sumrates = torch.sum(rates)\n",
    "        p0 = torch.exp(-sumrates * dt)\n",
    "        m = torch.distributions.Multinomial(total_count=N, probs=torch.cat([p0.reshape(1), (1-p0)*rates/sumrates]))\n",
    "        samp = m.sample()\n",
    "        if save:\n",
    "            self.s_m = m\n",
    "            self.s_num = samp\n",
    "        return samp\n",
    "        \n",
    "    \n",
    "    #@torch.jit.script_method\n",
    "    def step(self):\n",
    "        pop = self.S + self.E + self.I + self.R\n",
    "        births = torch.distributions.Poisson(self.mu * self.dt * pop).sample() #* pop\n",
    "        beta = torch.exp(torch.dot(self.betas, self.covars[self.t]) + (self.betat-215)/(430-215))\n",
    "        self.sig_mod = torch.distributions.Gamma(self.sig_sq, self.dt)\n",
    "        self.sig_num = self.sig_mod.sample()\n",
    "        foi = torch.pow(self.I, self.nu) * beta / pop * self.sig_num / self.dt\n",
    "        \n",
    "        s_rates = torch.cat([foi, self.delta])\n",
    "        e_rates = torch.cat([self.sigma, self.delta])\n",
    "        i_rates = torch.cat([self.gamma, self.delta])\n",
    "        r_rates = torch.cat([self.alpha, self.delta])\n",
    "        \n",
    "        s_num = self.reulermultinom(int(self.S), s_rates, self.dt, True) if int(self.S) > 0 else torch.tensor([0,0,0]).double()\n",
    "        e_num = self.reulermultinom(int(self.E), e_rates, self.dt) if int(self.E) > 0 else torch.tensor([0,0,0]).double()\n",
    "        i_num = self.reulermultinom(int(self.I), i_rates, self.dt) if int(self.I) > 0 else torch.tensor([0,0,0]).double()\n",
    "        r_num = self.reulermultinom(int(self.R), r_rates, self.dt) if int(self.R) > 0 else torch.tensor([0,0,0]).double()\n",
    "        \n",
    "        self.S = self.S.clone() + torch.tensor([0, -1, -1]).double().T @ s_num + r_num[1] + births\n",
    "        self.E = self.E.clone() + torch.tensor([0, -1, -1]).double().T @ e_num + s_num[1]\n",
    "        self.I = self.I.clone() + torch.tensor([0, -1, -1]).double().T @ i_num + e_num[1]\n",
    "        self.R = self.R.clone() + torch.tensor([0, -1, -1]).double().T @ r_num + i_num[1]\n",
    "        \n",
    "        self.incid += e_num[0]\n",
    "        self.foival += foi\n",
    "        \n",
    "    def rprocess(self):\n",
    "        for i in range(int(1/self.dt)):\n",
    "            self.step()\n",
    "        self.t += 1\n",
    "        \n",
    "    def rmeasure(self):\n",
    "        m = torch.distributions.negative_binomial.NegativeBinomial(\n",
    "            total_count=self.tau, probs = self.tau/(self.tau+(self.rho * self.incid)))\n",
    "        return m.sample()\n",
    "    \n",
    "    def dmeasure(self, case=None):\n",
    "        if case is None:\n",
    "            case = self.rmeasure()\n",
    "        m = torch.distributions.negative_binomial.NegativeBinomial(\n",
    "            total_count=self.tau, probs = self.tau/(self.tau+(self.rho * self.incid)))\n",
    "        return m.log_prob(case)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "fe07548a-4733-46db-b65f-d0676a79ca64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([10904842.2025], dtype=torch.float64), tensor([10869768.2025], dtype=torch.float64), tensor([10903181.2025], dtype=torch.float64)]\n",
      "[5091411808, 5090074480, 5090074432]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:05,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([10884585.2025], dtype=torch.float64), tensor([10906576.2025], dtype=torch.float64), tensor([10898639.2025], dtype=torch.float64)]\n",
      "[6220310080, 6220311472, 6220312240]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:07,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([10899244.2025], dtype=torch.float64), tensor([10909401.2025], dtype=torch.float64), tensor([10909675.2025], dtype=torch.float64)]\n",
      "[6220311856, 6220309360, 5090216256]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:10,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([10912677.2025], dtype=torch.float64), tensor([10907862.2025], dtype=torch.float64), tensor([10911991.2025], dtype=torch.float64)]\n",
      "[6220311760, 5090214864, 5090217840]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:13,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([10915826.2025], dtype=torch.float64), tensor([10915714.2025], dtype=torch.float64), tensor([10915838.2025], dtype=torch.float64)]\n",
      "[5090217216, 5090214096, 5090214384]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "def innerpfilter(particle):\n",
    "    particle.rprocess()\n",
    "    return particle\n",
    "\n",
    "def copyparams(source, target):\n",
    "    target.load_state_dict(source.state_dict())\n",
    "    target.S = source.S.clone()\n",
    "    target.E = source.E.clone()\n",
    "    target.I = source.I.clone()\n",
    "    target.R = source.R.clone()\n",
    "    target.incid = source.incid.clone()\n",
    "    target.foival = source.foival.clone()\n",
    "    \n",
    "    \n",
    "def pfilter(constructor = Haiti1, covars = covars, cases = cases, params = params, dt = 1/7, Np = 100):\n",
    "    loss1 = 0\n",
    "    loss2 = 0\n",
    "    loss3 = 0\n",
    "    loglik = None\n",
    "    particles = [[Haiti1(covars, cases, params, dt) for j in range(Np)]]\n",
    "        \n",
    "    for idx, case in tqdm(enumerate(cases)):\n",
    "        case = torch.tensor(case)\n",
    "        \n",
    "        for particle in particles[idx]:\n",
    "            particle.rprocess()\n",
    "        print([particle.S for particle in particles[idx]])\n",
    "        print([id(particle) for particle in particles[idx]])\n",
    "            \n",
    "        weights = [particle.dmeasure(case) for particle in particles[idx]]\n",
    "        weights = torch.cat(weights)\n",
    "\n",
    "        m = torch.distributions.Multinomial(total_count = Np, logits = weights)\n",
    "        counts = m.sample().int()\n",
    "        reward = torch.log(torch.mean(torch.exp(weights)))\n",
    "\n",
    "        loss1 += -m.log_prob(counts) * reward # reward here\n",
    "        for mod1 in particles[idx]:\n",
    "            loss2 += -mod1.s_m.log_prob(mod1.s_num) * reward / Np\n",
    "            loss3 += -mod1.sig_mod.log_prob(mod1.sig_num) * reward / Np\n",
    "        loglik = reward if loglik is None else loglik + reward\n",
    "        \n",
    "        newparticles = [Haiti1(covars, cases, params, dt) for j in range(Np)]\n",
    "        for i, count in enumerate(counts):\n",
    "            for j in range(count):\n",
    "                copyparams(particles[idx][i], newparticles[j])\n",
    "        particles.append(newparticles)\n",
    "        \n",
    "    lossfilter = loss1 + loss2 + loss3\n",
    "    return lossfilter, loglik, particles\n",
    "\n",
    "mod1 = Haiti1(covars, cases, params, 1/7)\n",
    "lossfilter, loglik, particles = pfilter(Haiti1, covars[:5], cases[:5], params, 1/7, Np = 3)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "cd3e1a0a-582a-438c-9ae8-a5f82364df9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([1.4376, 1.2902, 1.1677, 1.2758, 1.3620, 1.1530], dtype=torch.float64,\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0672], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([0.7618], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([266.0769], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([0.9649], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([0.1042], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([0.0002], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([0.0005], dtype=torch.float64, requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in mod1.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d2c272e2-7bdb-4570-afb5-751b8d6dd150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0914], dtype=torch.float64)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particles[0][0].tau.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "59ac7afd-c0ff-4b22-9ad7-461a4237b182",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "optim = torch.optim.Adam(particles[0][-1].parameters(), lr=5000)\n",
    "lossfilter.backward()\n",
    "#loglik.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "63a89fc8-a3be-4c93-9848-7897793f7dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([5001.4374, 5001.2901, 5001.1668, 5001.2234, 5001.3096, 5001.1521],\n",
      "       dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([4999.9172], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([2666.8420], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([228.5057], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([5000.9649], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([5000.1041], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([-4999.9997], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([5000.0005], dtype=torch.float64, requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "optim.step()\n",
    "print([p for p in particles[0][-1].parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d506e1-ab70-4b25-a68d-cd238da18545",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Testing\n",
    "\n",
    "This checks if the gradients flow through all parameters, using the log-likelihood given by `dmeasure` after a single step. If gradients indeed do propagate, you should expect to see very very high values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e59670a4-bf59-45f5-852f-cff46519b0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([-4998.5624, -4998.7098, -4998.8322, -4998.7230, -4998.6368, -4998.8469],\n",
      "       dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([-5000.0668], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([-4999.2382], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([5266.0764], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([-4999.0351], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([-4999.8958], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([5000.0002], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([-4999.9995], dtype=torch.float64, requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "mod1 = Haiti1(covars, cases, params, 1/7)\n",
    "mod1.rprocess()\n",
    "optim = torch.optim.Adam(mod1.parameters(), lr=5000) #turns out, only differentiable wrt rho and tau. Oh well.\n",
    "loss = -mod1.dmeasure()\n",
    "loss.backward(retain_graph=True)\n",
    "loss2 = mod1.s_m.log_prob(mod1.s_num) * loss\n",
    "loss2.backward(retain_graph=True)\n",
    "loss3 = mod1.sig_mod.log_prob(mod1.sig_num) * loss\n",
    "loss3.backward()\n",
    "optim.step()\n",
    "print([p for p in mod1.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acb81785-9f90-4150-92c3-489ae3d661a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([-4998.5622, -4998.7096, -4998.8313, -4998.6720, -4998.5859, -4998.8460],\n",
      "       dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([-5000.0516], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([5000.7618], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([-4733.9230], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([-4999.0351], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([-4999.8958], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([5000.0001], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([-4999.9995], dtype=torch.float64, requires_grad=True)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "36515d11-5617-474b-b911-3dff8b74b11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([1.4376, 1.2902, 1.1677, 1.2758, 1.3620, 1.1530], dtype=torch.float64,\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0672], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([0.7618], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([266.0769], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([0.9649], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([0.1042], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([0.0002], dtype=torch.float64, requires_grad=True), Parameter containing:\n",
      "tensor([0.0005], dtype=torch.float64, requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([ p for p in mod1.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd49c2-9236-44a4-b53c-beb64fe3547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "     self.betas = nn.Parameter(torch.tensor([params['beta1'], params['beta2'], \n",
    "                                                params['beta3'], params['beta4'], \n",
    "                                                params['beta5'], params['beta6']]).squeeze())\n",
    "        self.betat = nn.Parameter(torch.tensor(params['betat']))\n",
    "        self.rho = nn.Parameter(torch.tensor(params['rho']))\n",
    "        self.tau = nn.Parameter(torch.tensor(params['tau']))\n",
    "        self.nu = nn.Parameter(torch.tensor(params['nu']))\n",
    "        self.sig_sq = nn.Parameter(torch.tensor(params['sig_sq']))\n",
    "        self.E_0 = nn.Parameter(torch.tensor(params['E_0']))\n",
    "        self.I_0 = nn.Parameter(torch.tensor(params['I_0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "5c09064c-a9e4-4e73-9f8f-4bb9e8ddcc37",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Parameter' object has no attribute 'gradient'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nn/z5pzxnxs629_tnqpvr431_fm0000gn/T/ipykernel_39962/1414620672.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Parameter' object has no attribute 'gradient'"
     ]
    }
   ],
   "source": [
    "mod1.nu.gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1162e389-fb24-425d-8fd1-fc94ea1f8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1.rprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d927f7fc-65fe-4cfe-bb32-76f0170e76a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([152320.], dtype=torch.float64)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "532e968b-0492-454d-abcf-232b04a2a96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10904841.2025], dtype=torch.float64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod1.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc27ecff-0d2b-488b-8f21-a5ae0031dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "  incids <- c(\"incid += Etrans[0]; \\n \")\n",
    "  foi_val <- \"foival += foi; \\n \"\n",
    "  str0 <- \"Str0 += Strans[0]; \\n \"\n",
    "  sin <- c(\"Sin += Rtrans[0] + births; \\n \")\n",
    "  sout <- c(\"Sout += Strans[0] + Strans[1]; \\n \")\n",
    "  last <- c(foi_val, str0, sin)\n",
    "\n",
    "\n",
    " ## dmeasure\n",
    "  dmeas <- Csnippet(\"\n",
    "    if (ISNA(cases)) {\n",
    "      lik = (give_log) ? 0 : 1;\n",
    "    } else {\n",
    "      lik = dnbinom_mu(cases, tau, rho*incid, give_log);\n",
    "    }\n",
    "  \")\n",
    "\n",
    "  ## rmeasure\n",
    "  rmeas <- Csnippet(\n",
    "    \"cases = rnbinom_mu(tau, rho*incid);\n",
    "    if (cases > 0.0) {\n",
    "      cases = nearbyint(cases);\n",
    "    } else {\n",
    "      cases = 0.0;\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
